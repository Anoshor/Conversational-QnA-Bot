{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6, openai_api_key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \"what is the capital of India\"\n",
    "\n",
    "print(llm.invoke(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\USERS\\ANOSH\\ONEDRIVE\\DESKTOP\\PROJECTS\\CHABOT\\CHATBOT\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={\"temperature\":0, \"max_length\":64}, huggingfacehub_api_token = hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\USERS\\ANOSH\\ONEDRIVE\\DESKTOP\\PROJECTS\\CHABOT\\CHATBOT\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moscow\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"whats the capital of Russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.invoke(\"Act like a mobilechat assistant.. answer my query.. is my wifi on or off?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.invoke(\"Can u turn on my wifi?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Unfortunately, I am not able to turn on wifi as I am a text-based program and do not have access to physical devices. You will need to manually turn on your wifi through your device's settings or by using the physical button on your device.\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(\"Can u turn on my wifi?\")\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],\n",
    "                                 template= \"Tell me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"Tell me the capital of {country}\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"], template=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke(\"India\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Multiple chains using sequential chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "captial_prompt = \"Tell me the capital of {country}\"\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=[\"country\"], template=captial_prompt\n",
    ")\n",
    "\n",
    "captial_chain = prompt1 | llm\n",
    "\n",
    "famous_prompt = \"Suggest me some amazing places to visit in {capital}\"\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['capital'], template=famous_prompt\n",
    ")\n",
    "\n",
    "famous_chain = llm | prompt2\n",
    "\n",
    "famous_chain.invoke(\"New Delhi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleSequentialChain\n\u001b[1;32m----> 3\u001b[0m chainoutput \u001b[39m=\u001b[39m SimpleSequentialChain(chains\u001b[39m=\u001b[39;49m[captial_chain, famous_chain])\n\u001b[0;32m      5\u001b[0m chainoutput\u001b[39m.\u001b[39minvoke(\u001b[39m\"\u001b[39m\u001b[39mIndia\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\USERS\\ANOSH\\ONEDRIVE\\DESKTOP\\PROJECTS\\CHABOT\\CHATBOT\\lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m, data)\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32mc:\\USERS\\ANOSH\\ONEDRIVE\\DESKTOP\\PROJECTS\\CHABOT\\CHATBOT\\lib\\site-packages\\pydantic\\v1\\main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     values \u001b[39m=\u001b[39m validator(cls_, values)\n\u001b[0;32m   1101\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m, \u001b[39mAssertionError\u001b[39;00m) \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m   1102\u001b[0m     errors\u001b[39m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[39m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32mc:\\USERS\\ANOSH\\ONEDRIVE\\DESKTOP\\PROJECTS\\CHABOT\\CHATBOT\\lib\\site-packages\\langchain\\chains\\sequential.py:158\u001b[0m, in \u001b[0;36mSimpleSequentialChain.validate_chains\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@root_validator\u001b[39m()\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_chains\u001b[39m(\u001b[39mcls\u001b[39m, values: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict:\n\u001b[0;32m    157\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate that chains are all single input/output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mfor\u001b[39;00m chain \u001b[39min\u001b[39;00m values[\u001b[39m\"\u001b[39;49m\u001b[39mchains\u001b[39;49m\u001b[39m\"\u001b[39;49m]:\n\u001b[0;32m    159\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(chain\u001b[39m.\u001b[39minput_keys) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    160\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    161\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mChains used in SimplePipeline should all have one input, got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mchain\u001b[39m}\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(chain\u001b[39m.\u001b[39minput_keys)\u001b[39m}\u001b[39;00m\u001b[39m inputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m             )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'chains'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chainoutput = SimpleSequentialChain(chains=[captial_chain, famous_chain])\n",
    "\n",
    "chainoutput.invoke(\"India\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHATMODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(temperature=0.6, openai_api_key = key, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\USERS\\ANOSH\\ONEDRIVE\\DESKTOP\\PROJECTS\\CHABOT\\CHATBOT\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! To turn on your WiFi, follow these steps:\\n\\n1. Unlock your phone and go to the home screen.\\n2. Open the Settings app. It usually looks like a gear icon.\\n3. Look for the \"Connections\" or \"Network & Internet\" option and tap on it.\\n4. Find the \"WiFi\" option and toggle the switch to turn it on. It may also be labeled as \"Wireless & Networks\" or something similar.\\n5. Your phone will start scanning for available WiFi networks. Select your desired network and enter the password if required.\\n6. Once connected, you should see the WiFi symbol appear in the status bar of your phone.\\n\\nThat\\'s it! Your WiFi should now be turned on and connected to the network. Let me know if you need any further assistance.', response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 27, 'total_tokens': 189}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-79c2ff57-72f0-4837-a423-615481bdddd5-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a phone ai assistant\"),\n",
    "    HumanMessage(content=\"Please provide me the steps to turn on my wifi\")\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful phone ai assistant. WHenever the user gives any input, you have to generate 5 synonymous words, in a comma seperated list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{text}\"\n",
    "\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' knowledgeable', ' sharp', ' astute']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43c5603f39000b7a460d7eaf773614009d8df13120dd1326dbd220edc4ad402a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
